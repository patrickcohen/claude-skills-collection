---
name: ln-633-test-value-auditor
description: Risk-Based Value audit worker (L3). Calculates Usefulness Score = Impact (1-5) × Probability (1-5) for each test. Returns KEEP/REVIEW/REMOVE decisions based on thresholds (≥15 KEEP, 10-14 REVIEW, <10 REMOVE).
allowed-tools: Read, Grep, Glob, Bash
---

> **Paths:** File paths (`shared/`, `references/`, `../ln-*`) are relative to skills repo root. If not found at CWD, locate this SKILL.md directory and go up one level for repo root.

# Risk-Based Value Auditor (L3 Worker)

Specialized worker calculating Usefulness Score for each test.

## Purpose & Scope

- **Worker in ln-630 coordinator pipeline**
- Audit **Risk-Based Value** (Category 3: Critical Priority)
- Calculate Usefulness Score = Impact × Probability
- Make KEEP/REVIEW/REMOVE decisions
- Calculate compliance score (X/10)

## Inputs (from Coordinator)

Receives `contextStore` with Impact/Probability matrices, test file list.

## Workflow

1) Parse context
2) For each test: calculate Usefulness Score
3) Classify: KEEP (≥15), REVIEW (10-14), REMOVE (<10)
4) Collect findings
5) Calculate score
6) Return JSON

## Usefulness Score Calculation

### Formula

```
Usefulness Score = Business Impact (1-5) × Failure Probability (1-5)
```

### Impact Scoring (1-5)

| Score | Impact | Examples |
|-------|--------|----------|
| **5** | **Critical** | Money loss, security breach, data corruption |
| **4** | **High** | Core flow breaks (checkout, login, registration) |
| **3** | **Medium** | Feature partially broken, degraded UX |
| **2** | **Low** | Minor UX issue, cosmetic bug |
| **1** | **Trivial** | Cosmetic issue, no user impact |

### Probability Scoring (1-5)

| Score | Probability | Indicators |
|-------|-------------|------------|
| **5** | **Very High** | Complex algorithm, new technology, many dependencies |
| **4** | **High** | Multiple dependencies, concurrency, edge cases |
| **3** | **Medium** | Standard CRUD, framework defaults, established patterns |
| **2** | **Low** | Simple logic, well-established library, trivial operation |
| **1** | **Very Low** | Trivial assignment, framework-generated, impossible to break |

### Decision Thresholds

| Score Range | Decision | Action |
|-------------|----------|--------|
| **≥15** | **KEEP** | Test is valuable, maintain it |
| **10-14** | **REVIEW** | Consider if E2E already covers this |
| **<10** | **REMOVE** | Delete test, not worth maintenance cost |

## Scoring Examples

### Example 1: Payment Processing Test

```
Test: "processPayment calculates discount correctly"
Impact: 5 (Critical — money calculation)
Probability: 4 (High — complex algorithm, multiple payment gateways)
Usefulness Score = 5 × 4 = 20
Decision: KEEP
```

### Example 2: Email Validation Test

```
Test: "validateEmail returns true for valid email"
Impact: 2 (Low — minor UX issue if broken)
Probability: 2 (Low — simple regex, well-tested library)
Usefulness Score = 2 × 2 = 4
Decision: REMOVE (likely already covered by E2E registration test)
```

### Example 3: Login Flow Test

```
Test: "login with valid credentials returns JWT"
Impact: 4 (High — core flow)
Probability: 3 (Medium — standard auth flow)
Usefulness Score = 4 × 3 = 12
Decision: REVIEW (if E2E covers, remove; else keep)
```

## Audit Rules

### 1. Calculate Score for Each Test

**Process:**
- Read test file, extract test name/description
- Analyze code under test (CUT)
- Determine Impact (1-5)
- Determine Probability (1-5)
- Calculate Usefulness Score

### 2. Classify Decisions

**KEEP (≥15):**
- High-value tests (money, security, data integrity)
- Core flows (checkout, login)
- Complex algorithms

**REVIEW (10-14):**
- Medium-value tests
- Question: "Is this already covered by E2E?"
- If yes → REMOVE; if no → KEEP

**REMOVE (<10):**
- Low-value tests (cosmetic, trivial)
- Framework/library tests
- Duplicates of E2E tests

### 3. Identify Patterns

**Common low-value tests (<10):**
- Testing framework behavior
- Testing trivial getters/setters
- Testing constant values
- Testing type annotations

## Scoring Algorithm

**MANDATORY READ:** Load `shared/references/audit_scoring.md` for unified scoring formula.

**Severity mapping by Usefulness Score:**
- Score <5 → CRITICAL (test wastes significant maintenance effort)
- Score 5-9 → HIGH (test likely wasteful)
- Score 10-14 → MEDIUM (review needed)
- Score ≥15 → no issue (KEEP)

## Output Format

**Return JSON to coordinator:**
```json
{
  "category": "Risk-Based Value",
  "score": 7,
  "total_issues": 12,
  "critical": 2,
  "high": 5,
  "medium": 5,
  "low": 0,
  "checks": [
    {"id": "usefulness_score", "name": "Usefulness Score Analysis", "status": "warning", "details": "7 tests scored below threshold 15"},
    {"id": "remove_candidates", "name": "Remove Candidates", "status": "failed", "details": "2 tests with Score <10 should be removed"},
    {"id": "review_candidates", "name": "Review Candidates", "status": "warning", "details": "5 tests with Score 10-14 need review"}
  ],
  "findings": [
    {
      "severity": "CRITICAL",
      "location": "utils.test.ts:23-27",
      "issue": "Test 'validateEmail returns true' has Usefulness Score 4 (Impact 2 × Probability 2) — REMOVE",
      "principle": "Risk-Based Value / Low Priority Test",
      "recommendation": "Delete test — likely covered by E2E registration test",
      "effort": "S"
    },
    {
      "severity": "MEDIUM",
      "location": "auth.test.ts:12-25",
      "issue": "Test 'login with valid credentials returns JWT' has Usefulness Score 12 (Impact 4 × Probability 3) — REVIEW",
      "principle": "Risk-Based Value / Borderline Test",
      "recommendation": "If E2E login test exists → delete; otherwise keep",
      "effort": "S"
    }
  ]
}
```

**Note:** Tests with Usefulness Score ≥15 (KEEP) are NOT included in findings — only issues are reported.

## Critical Rules

- **Do not auto-fix:** Report only
- **Effort realism:** S = <1h, M = 1-4h, L = >4h
- **Score objectivity:** Base Impact and Probability on code analysis, not assumptions
- **KEEP tests not reported:** Only REVIEW and REMOVE decisions appear in findings
- **Cross-reference E2E:** REVIEW decisions depend on whether E2E already covers the scenario

## Definition of Done

- contextStore parsed (Impact/Probability matrices, test file list)
- Usefulness Score calculated for each test (Impact x Probability)
- Decisions classified: KEEP (>=15), REVIEW (10-14), REMOVE (<10)
- Findings collected with severity, location, effort, recommendation
- Score calculated per `shared/references/audit_scoring.md`
- JSON returned to coordinator

## Reference Files

- **Audit scoring formula:** `shared/references/audit_scoring.md`
- **Audit output schema:** `shared/references/audit_output_schema.md`

---
**Version:** 3.0.0
**Last Updated:** 2025-12-23
